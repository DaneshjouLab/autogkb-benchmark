"""
Pharmacogenomics Knowledge Extraction Pipeline

This pipeline links together the results from different experiments to generate
one cohesive output per PMCID that includes:
- Found variants
- Association sentences
- Supporting citations
- Summary

The pipeline stores model and prompt configurations in the output for reproducibility.
It does not store judging results, only the findings generated by each module.

Output Structure:
  Each PMCID result is saved to its own file immediately after processing:
  outputs/{config_name}/{PMCID}.json

  This enables incremental processing and easy access to individual results.

Example Commands:

1. Run pipeline for a single PMCID:
   python pipeline.py --num-pmcids 1

2. Run pipeline for all PMCIDs in benchmark:
   python pipeline.py

3. Run with custom config file:
   python pipeline.py --config configs/my_config.yaml

4. Run specific stages only:
   python pipeline.py --stages variants,sentences

5. Run specific PMCIDs:
   python pipeline.py --pmcids PMC123456 PMC789012
"""

from __future__ import annotations

import argparse
import json
import re
import sys
import warnings
from dataclasses import dataclass, field, asdict
from datetime import datetime
from pathlib import Path
from typing import Any

import yaml
from dotenv import load_dotenv
from loguru import logger

# Suppress Pydantic serialization warnings from litellm
warnings.filterwarnings("ignore", category=UserWarning, module="pydantic.main")

# Load environment (API keys, etc.)
load_dotenv()

# Paths
PIPELINE_DIR = Path(__file__).resolve().parent
ROOT = PIPELINE_DIR.parents[1]

# Add repository root to Python path to enable imports
if str(ROOT) not in sys.path:
    sys.path.insert(0, str(ROOT))

# Import utilities from experiments
from src.experiments.utils import (
    call_llm,
    get_markdown_text,
    get_methods_and_conclusions_text,
)

# Import regex variant extraction functions
from src.experiments.variant_finding.regex_variants.extract_variants_v5 import (
    extract_all_variants,
    get_combined_text,
    get_snp_expander,
)

# Default paths within pipeline folder
CONFIGS_DIR = PIPELINE_DIR / "configs"
CONFIG_FILE = CONFIGS_DIR / "base_config.yaml"
PROMPTS_FILE = PIPELINE_DIR / "prompts.yaml"
OUTPUTS_DIR = PIPELINE_DIR / "outputs"
VARIANT_BENCH_PATH = ROOT / "data" / "benchmark_v2" / "variant_bench.jsonl"


# =============================================================================
# DATA CLASSES
# =============================================================================


@dataclass
class VariantResult:
    """Result of variant extraction for a single variant."""

    variant_id: str
    sentence: str = ""
    explanation: str = ""
    citations: list[str] = field(default_factory=list)


@dataclass
class PMCIDResult:
    """Complete pipeline result for a single PMCID."""

    pmcid: str
    variants: list[str] = field(default_factory=list)
    variant_extraction_metadata: dict = field(default_factory=dict)
    associations: list[VariantResult] = field(default_factory=list)
    summary: str = ""

    def to_dict(self) -> dict:
        """Convert to dictionary for JSON serialization."""
        return {
            "pmcid": self.pmcid,
            "variants": self.variants,
            "variant_extraction_metadata": self.variant_extraction_metadata,
            "associations": [asdict(a) for a in self.associations],
            "summary": self.summary,
        }


@dataclass
class PipelineOutput:
    """Complete pipeline output including metadata and results."""

    metadata: dict
    results: list[PMCIDResult]

    def to_dict(self) -> dict:
        """Convert to dictionary for JSON serialization."""
        return {
            "metadata": self.metadata,
            "results": [r.to_dict() for r in self.results],
        }


# =============================================================================
# CONFIGURATION LOADING
# =============================================================================


def load_config(config_path: Path = CONFIG_FILE) -> dict:
    """Load pipeline configuration from YAML file."""
    logger.debug(f"Loading config from {config_path}")
    with open(config_path) as f:
        config = yaml.safe_load(f)
    logger.info(f"Loaded config with stages: {list(config.keys())}")
    return config


def load_prompts(prompts_path: Path = PROMPTS_FILE) -> dict:
    """Load all prompts from YAML file."""
    logger.debug(f"Loading prompts from {prompts_path}")
    with open(prompts_path) as f:
        prompts = yaml.safe_load(f)
    logger.info(f"Loaded prompts for stages: {list(prompts.keys())}")
    return prompts


def get_pmcids_from_benchmark(num_pmcids: int | None = None) -> list[str]:
    """Get list of PMCIDs from the variant benchmark file.

    Args:
        num_pmcids: Number of PMCIDs to return. None means all.

    Returns:
        List of PMCID strings.
    """
    logger.debug(f"Loading PMCIDs from {VARIANT_BENCH_PATH}")
    pmcids = []
    with open(VARIANT_BENCH_PATH) as f:
        for line in f:
            if not line.strip():
                continue
            rec = json.loads(line)
            pmcids.append(rec["pmcid"])
            if num_pmcids and len(pmcids) >= num_pmcids:
                break
    logger.info(f"Loaded {len(pmcids)} PMCID(s)")
    return pmcids


# =============================================================================
# VARIANT EXTRACTION STAGE (Regex-based)
# =============================================================================

# Global flag to track if SNP expander has been initialized
_snp_expander_initialized = False


def initialize_variant_extraction():
    """Initialize the SNP expander for variant extraction (called once at pipeline start)."""
    global _snp_expander_initialized
    if not _snp_expander_initialized:
        logger.info("Initializing SNP expander for variant extraction...")
        expander = get_snp_expander()
        stats = expander.stats()
        logger.info(f"  Loaded {stats['total_mappings']} SNP notation mappings")
        logger.info(
            f"  Covering {stats['unique_rsids']} unique rsIDs across {len(stats['genes'])} genes"
        )
        _snp_expander_initialized = True


def extract_variants(pmcid: str) -> tuple[list[str], dict]:
    """Extract pharmacogenetic variants from an article using regex patterns.

    Uses regex-based extraction v5 with:
    - rsID extraction (rs#####)
    - Star allele extraction (GENE*#)
    - HLA allele extraction (HLA-X*##:##)
    - SNP notation expansion (e.g., CYP2B6 516G>T -> rs3745274)
    - BioC API for supplementary material text

    Args:
        pmcid: PMCID of the article

    Returns:
        Tuple of (list of variant identifiers, extraction metadata dict).
    """
    logger.info(f"Extracting variants from {pmcid} using regex patterns")

    # Get combined article + supplement text
    combined_text, supplement_text = get_combined_text(pmcid)

    if not combined_text:
        logger.warning(f"No article text found for {pmcid}")
        return [], {"has_supplement": False, "supplement_variants": []}

    # Extract all variants using regex patterns
    variants = extract_all_variants(combined_text)

    # Track which variants came from supplements (for metadata)
    article_only_text = get_markdown_text(pmcid)
    article_only_variants = (
        extract_all_variants(article_only_text) if article_only_text else []
    )
    supplement_only_variants = list(set(variants) - set(article_only_variants))

    metadata = {
        "has_supplement": supplement_text is not None,
        "supplement_variants": supplement_only_variants,
        "total_extracted": len(variants),
        "from_article": len(article_only_variants),
        "from_supplement": len(supplement_only_variants),
    }

    logger.info(
        f"Extracted {len(variants)} variant(s) from {pmcid} "
        f"(article: {len(article_only_variants)}, supplement: {len(supplement_only_variants)})"
    )

    return variants, metadata


# =============================================================================
# SENTENCE GENERATION STAGE
# =============================================================================


def parse_sentence_output(
    output: str,
    use_explanations: bool = True,
) -> dict[str, dict[str, str]]:
    """Parse batch sentence generation output.

    Args:
        output: LLM output text
        use_explanations: Whether to expect EXPLANATION fields

    Returns:
        Dictionary mapping variant_id -> {sentence, explanation}
    """
    result: dict[str, dict[str, str]] = {}

    if use_explanations:
        # Pattern for v4/v5: VARIANT, SENTENCE, and EXPLANATION
        pattern = r"VARIANT:\s*(.+?)\s*\n\s*SENTENCE:\s*(.+?)\s*\n\s*EXPLANATION:\s*(.+?)(?=\n\s*VARIANT:|$)"
        matches = re.findall(pattern, output, re.DOTALL | re.IGNORECASE)

        for match in matches:
            variant_id = match[0].strip()
            sentence = match[1].strip()
            explanation = match[2].strip()
            result[variant_id] = {"sentence": sentence, "explanation": explanation}
            logger.debug(f"Parsed variant {variant_id} with explanation")
    else:
        # Pattern for v3: VARIANT and SENTENCE only
        pattern = r"VARIANT:\s*(.+?)\s*\n\s*SENTENCE:\s*(.+?)(?=\n\s*VARIANT:|$)"
        matches = re.findall(pattern, output, re.DOTALL | re.IGNORECASE)

        for match in matches:
            variant_id = match[0].strip()
            sentence = match[1].strip()
            result[variant_id] = {"sentence": sentence, "explanation": ""}
            logger.debug(f"Parsed variant {variant_id}")

    if not result:
        logger.warning("Failed to parse any variants from sentence output")
        logger.debug(f"Output was: {output[:500]}...")

    return result


def generate_sentences(
    pmcid: str,
    variants: list[str],
    model: str,
    prompt_cfg: dict,
    prompt_version: str,
) -> list[VariantResult]:
    """Generate association sentences for variants.

    Args:
        pmcid: PMCID of the article
        variants: List of variant identifiers
        model: Model to use for generation
        prompt_cfg: Prompt configuration
        prompt_version: Which prompt version is being used

    Returns:
        List of VariantResult objects with sentences and explanations.
    """
    if not variants:
        logger.warning(f"No variants provided for {pmcid}")
        return []

    logger.info(f"Generating sentences for {len(variants)} variant(s) in {pmcid}")

    # Get article text
    article_text = get_methods_and_conclusions_text(pmcid)
    if not article_text:
        article_text = get_markdown_text(pmcid)

    if not article_text:
        logger.warning(f"No article text found for {pmcid}")

    # Determine if we're using explanations (v4/v5)
    use_explanations = prompt_version in ("v4", "v5")

    # Format variants list
    variants_list = "\n".join([f"- {v}" for v in variants])

    # Format prompt
    user_prompt = prompt_cfg["user"].format(
        variants_list=variants_list,
        article_text=article_text or "[Article text not available]",
    )
    system_prompt = prompt_cfg["system"]

    # Call LLM
    try:
        response = call_llm(model, system_prompt, user_prompt)
        parsed = parse_sentence_output(response, use_explanations)
    except Exception as e:
        logger.error(f"Error generating sentences for {pmcid}: {e}")
        parsed = {}

    # Build results
    results: list[VariantResult] = []
    for variant in variants:
        if variant in parsed:
            results.append(
                VariantResult(
                    variant_id=variant,
                    sentence=parsed[variant]["sentence"],
                    explanation=parsed[variant]["explanation"],
                )
            )
            logger.debug(f"✓ {variant}: sentence generated")
        else:
            results.append(VariantResult(variant_id=variant))
            logger.warning(f"✗ {variant}: not found in output")

    logger.info(
        f"Generated {len([r for r in results if r.sentence])} sentence(s) for {pmcid}"
    )
    return results


# =============================================================================
# CITATION FINDING STAGE
# =============================================================================


def parse_citation_output(output: str) -> dict[int, list[str]]:
    """Parse citation finding output.

    Args:
        output: LLM output text

    Returns:
        Dictionary mapping association index (1-indexed) -> list of citations.
    """
    result: dict[int, list[str]] = {}

    # Split by ASSOCIATION: markers
    assoc_blocks = re.split(r"\n\s*ASSOCIATION:\s*", output)

    for block in assoc_blocks:
        if not block.strip():
            continue

        lines = block.strip().split("\n")
        if not lines:
            continue

        assoc_line = lines[0].strip()
        # Remove "ASSOCIATION:" prefix if present
        if assoc_line.upper().startswith("ASSOCIATION:"):
            assoc_line = assoc_line[12:].strip()

        # Parse the association index
        try:
            assoc_idx = int(assoc_line)
        except ValueError:
            logger.warning(f"Could not parse association index: {assoc_line}")
            continue

        # Find CITATIONS: section
        citations = []
        in_citations = False

        for line in lines[1:]:
            line = line.strip()
            if line.upper().startswith("CITATIONS:"):
                in_citations = True
                continue

            if in_citations and line:
                # Remove leading numbers like "1. " or "1) "
                citation = re.sub(r"^\d+[\.)]\s*", "", line)
                citation = citation.strip().strip('"').strip("'").strip("\\")
                citation = re.sub(r"^[\\\"\']+|[\\\"\']+$", "", citation)
                if citation:
                    citations.append(citation)

        if citations:
            result[assoc_idx] = citations
            logger.debug(
                f"Parsed {len(citations)} citation(s) for association {assoc_idx}"
            )

    if not result:
        logger.warning("Failed to parse any citations from output")

    return result


def find_citations(
    pmcid: str,
    associations: list[VariantResult],
    model: str,
    prompt_cfg: dict,
    prompt_version: str,
) -> list[VariantResult]:
    """Find supporting citations for association sentences.

    Args:
        pmcid: PMCID of the article
        associations: List of VariantResult objects with sentences
        model: Model to use for citation finding
        prompt_cfg: Prompt configuration
        prompt_version: Which prompt version is being used

    Returns:
        Updated list of VariantResult objects with citations added.
    """
    # Filter to only associations with sentences
    valid_associations = [a for a in associations if a.sentence]

    if not valid_associations:
        logger.warning(f"No valid associations to find citations for in {pmcid}")
        return associations

    logger.info(
        f"Finding citations for {len(valid_associations)} association(s) in {pmcid}"
    )

    # Get full article text for citation search
    article_text = get_markdown_text(pmcid)
    if not article_text:
        logger.warning(f"No article text found for {pmcid}")
        return associations

    # Format associations for the prompt (with explanations if v2)
    if prompt_version == "v2":
        associations_text = "\n\n".join(
            [
                f"ASSOCIATION {i + 1}:\n- Variant: {a.variant_id}\n- Sentence: {a.sentence}\n- Explanation: {a.explanation}"
                for i, a in enumerate(valid_associations)
            ]
        )
    else:
        associations_text = "\n\n".join(
            [
                f"ASSOCIATION {i + 1}:\n- Variant: {a.variant_id}\n- Sentence: {a.sentence}"
                for i, a in enumerate(valid_associations)
            ]
        )

    # Format prompt
    user_prompt = prompt_cfg["user"].format(
        associations=associations_text,
        article_text=article_text,
    )
    system_prompt = prompt_cfg["system"]

    # Call LLM
    try:
        response = call_llm(model, system_prompt, user_prompt)
        citation_map = parse_citation_output(response)
    except Exception as e:
        logger.error(f"Error finding citations for {pmcid}: {e}")
        citation_map = {}

    # Update associations with citations
    for i, assoc in enumerate(valid_associations):
        assoc_idx = i + 1  # 1-indexed
        assoc.citations = citation_map.get(assoc_idx, [])
        if assoc.citations:
            logger.debug(f"✓ {assoc.variant_id}: {len(assoc.citations)} citation(s)")
        else:
            logger.warning(f"✗ {assoc.variant_id}: no citations found")

    citations_found = sum(1 for a in valid_associations if a.citations)
    logger.info(
        f"Found citations for {citations_found}/{len(valid_associations)} association(s) in {pmcid}"
    )

    return associations


# =============================================================================
# SUMMARY GENERATION STAGE
# =============================================================================


def format_associations_for_summary(associations: list[VariantResult]) -> str:
    """Format associations for summary prompt."""
    valid = [a for a in associations if a.sentence]
    if not valid:
        return "No associations found"

    parts = []
    for i, a in enumerate(valid, 1):
        parts.append(f"{i}. {a.variant_id}:\n  - {a.sentence}")

    return "\n\n".join(parts)


def format_citations_for_summary(associations: list[VariantResult]) -> str:
    """Format citations for summary prompt."""
    valid = [a for a in associations if a.citations]
    if not valid:
        return "No citations available"

    parts = []
    for a in valid:
        citations_text = "\n    - ".join(a.citations[:3])  # Limit to top 3
        parts.append(f"For '{a.variant_id}':\n    - {citations_text}")

    return "\n\n".join(parts)


def generate_summary(
    pmcid: str,
    associations: list[VariantResult],
    model: str,
    prompt_cfg: dict,
) -> str:
    """Generate a summary of pharmacogenomic findings.

    Args:
        pmcid: PMCID of the article
        associations: List of VariantResult objects with sentences and citations
        model: Model to use for summary generation
        prompt_cfg: Prompt configuration

    Returns:
        Summary text.
    """
    logger.info(f"Generating summary for {pmcid}")

    # Get article text
    article_text = get_markdown_text(pmcid)
    if not article_text:
        article_text = "[Article text not available]"

    # Format associations and citations
    associations_text = format_associations_for_summary(associations)
    citations_text = format_citations_for_summary(associations)

    # Format prompt
    user_prompt = prompt_cfg["user"].format(
        article_text=article_text,
        associations=associations_text,
        citations=citations_text,
    )
    system_prompt = prompt_cfg["system"]

    # Call LLM
    try:
        summary = call_llm(model, system_prompt, user_prompt)
        logger.info(f"Generated summary for {pmcid} ({len(summary)} chars)")
        return summary
    except Exception as e:
        logger.error(f"Error generating summary for {pmcid}: {e}")
        return f"[Error generating summary: {e}]"


# =============================================================================
# OUTPUT HELPERS
# =============================================================================


def save_pmcid_result(
    result: PMCIDResult,
    output_dir: Path,
    metadata: dict,
) -> Path:
    """Save a single PMCID result to its own file.

    Args:
        result: PMCIDResult to save
        output_dir: Directory to save the file in
        metadata: Pipeline metadata to include

    Returns:
        Path to the saved file.
    """
    output_dir.mkdir(parents=True, exist_ok=True)
    out_path = output_dir / f"{result.pmcid}.json"

    output_data = {
        "metadata": metadata,
        "result": result.to_dict(),
    }

    with open(out_path, "w", encoding="utf-8") as f:
        json.dump(output_data, f, indent=2, ensure_ascii=False)

    logger.info(f"Saved result to: {out_path}")
    return out_path


# =============================================================================
# PIPELINE ORCHESTRATION
# =============================================================================


def process_pmcid(
    pmcid: str,
    config: dict,
    prompts: dict,
    stages: set[str],
) -> PMCIDResult:
    """Process a single PMCID through the pipeline.

    Args:
        pmcid: PMCID to process
        config: Pipeline configuration
        prompts: All prompts
        stages: Set of stages to run

    Returns:
        PMCIDResult with all findings.
    """
    logger.info(f"\n{'=' * 60}")
    logger.info(f"Processing PMCID: {pmcid}")
    logger.info(f"{'=' * 60}")

    result = PMCIDResult(pmcid=pmcid)

    # Stage 1: Variant Extraction (Regex-based)
    if "variants" in stages:
        result.variants, result.variant_extraction_metadata = extract_variants(pmcid)

    # Stage 2: Sentence Generation
    if "sentences" in stages and result.variants:
        sentence_cfg = config["sentence_generation"]
        prompt_version = sentence_cfg["prompt_version"]
        prompt_cfg = prompts["sentence_generation"][prompt_version]

        result.associations = generate_sentences(
            pmcid=pmcid,
            variants=result.variants,
            model=sentence_cfg["model"],
            prompt_cfg=prompt_cfg,
            prompt_version=prompt_version,
        )

    # Stage 3: Citation Finding
    if "citations" in stages and result.associations:
        citation_cfg = config["citation_finding"]
        prompt_version = citation_cfg["prompt_version"]
        prompt_cfg = prompts["citation_finding"][prompt_version]

        result.associations = find_citations(
            pmcid=pmcid,
            associations=result.associations,
            model=citation_cfg["model"],
            prompt_cfg=prompt_cfg,
            prompt_version=prompt_version,
        )

    # Stage 4: Summary Generation
    if "summary" in stages:
        summary_cfg = config["summary_generation"]
        prompt_version = summary_cfg["prompt_version"]
        prompt_cfg = prompts["summary_generation"][prompt_version]

        result.summary = generate_summary(
            pmcid=pmcid,
            associations=result.associations,
            model=summary_cfg["model"],
            prompt_cfg=prompt_cfg,
        )

    # Log summary
    logger.info(f"\nResults for {pmcid}:")
    logger.info(f"  Variants found: {len(result.variants)}")
    logger.info(
        f"  Associations: {len([a for a in result.associations if a.sentence])}"
    )
    logger.info(
        f"  With citations: {len([a for a in result.associations if a.citations])}"
    )
    logger.info(f"  Summary generated: {'Yes' if result.summary else 'No'}")

    return result


def run_pipeline(
    pmcids: list[str],
    config: dict,
    prompts: dict,
    stages: set[str],
    output_dir: Path,
) -> tuple[Path, list[PMCIDResult]]:
    """Run the full pipeline on multiple PMCIDs.

    Each PMCID result is saved to its own file immediately after processing.

    Args:
        pmcids: List of PMCIDs to process
        config: Pipeline configuration
        prompts: All prompts
        stages: Set of stages to run
        output_dir: Directory to save individual PMCID result files

    Returns:
        Tuple of (output_dir, list of PMCIDResults).
    """
    timestamp = datetime.now().isoformat()

    # Initialize variant extraction if needed
    if "variants" in stages:
        initialize_variant_extraction()

    # Build metadata - include config name for reproducibility
    config_info = config.get("config", {})
    metadata = {
        "timestamp": timestamp,
        "config_name": config_info.get("name", "unknown"),
        "config_description": config_info.get("description", ""),
        "stages_run": list(stages),
        "pipeline_config": {
            "variant_extraction": {
                "method": config["variant_extraction"]["method"],
                "version": config["variant_extraction"]["version"],
                "description": config["variant_extraction"]["description"],
            },
            "sentence_generation": {
                "model": config["sentence_generation"]["model"],
                "prompt_version": config["sentence_generation"]["prompt_version"],
            },
            "citation_finding": {
                "model": config["citation_finding"]["model"],
                "prompt_version": config["citation_finding"]["prompt_version"],
            },
            "summary_generation": {
                "model": config["summary_generation"]["model"],
                "prompt_version": config["summary_generation"]["prompt_version"],
            },
        },
    }

    # Ensure output directory exists
    output_dir.mkdir(parents=True, exist_ok=True)

    # Process each PMCID and save immediately
    results: list[PMCIDResult] = []
    for i, pmcid in enumerate(pmcids, 1):
        logger.info(f"\n[{i}/{len(pmcids)}] Processing {pmcid}")
        try:
            result = process_pmcid(pmcid, config, prompts, stages)
            results.append(result)
            # Save result immediately after processing
            save_pmcid_result(result, output_dir, metadata)
        except Exception as e:
            logger.error(f"Failed to process {pmcid}: {e}")
            error_result = PMCIDResult(pmcid=pmcid)
            results.append(error_result)
            # Still save error result so we know it was attempted
            save_pmcid_result(error_result, output_dir, metadata)

    return output_dir, results


def main():
    parser = argparse.ArgumentParser(
        description="Run the pharmacogenomics knowledge extraction pipeline."
    )
    parser.add_argument(
        "--config",
        type=Path,
        default=CONFIG_FILE,
        help=f"Path to config YAML file (default: {CONFIG_FILE})",
    )
    parser.add_argument(
        "--prompts",
        type=Path,
        default=PROMPTS_FILE,
        help=f"Path to prompts YAML file (default: {PROMPTS_FILE})",
    )
    parser.add_argument(
        "--num-pmcids",
        type=int,
        default=None,
        help="Number of PMCIDs to process (default: all)",
    )
    parser.add_argument(
        "--pmcids",
        nargs="+",
        default=None,
        help="Specific PMCIDs to process (overrides --num-pmcids)",
    )
    parser.add_argument(
        "--stages",
        default="variants,sentences,citations,summary",
        help="Comma-separated list of stages to run (default: all)",
    )
    args = parser.parse_args()

    # Load configuration
    config = load_config(args.config)
    prompts = load_prompts(args.prompts)

    # Get PMCIDs
    if args.pmcids:
        pmcids = args.pmcids
    else:
        pmcids = get_pmcids_from_benchmark(args.num_pmcids)

    # Parse stages
    stages = set(s.strip() for s in args.stages.split(","))
    valid_stages = {"variants", "sentences", "citations", "summary"}
    invalid_stages = stages - valid_stages
    if invalid_stages:
        logger.error(f"Invalid stages: {invalid_stages}. Valid: {valid_stages}")
        sys.exit(1)

    config_info = config.get("config", {})
    logger.info(f"Pipeline Configuration:")
    logger.info(f"  Config: {config_info.get('name', 'unknown')}")
    logger.info(f"  PMCIDs to process: {len(pmcids)}")
    logger.info(f"  Stages: {sorted(stages)}")
    logger.info(
        f"  Variant extraction: {config['variant_extraction']['method']} {config['variant_extraction']['version']}"
    )
    logger.info(f"  Sentence model: {config['sentence_generation']['model']}")
    logger.info(f"  Citation model: {config['citation_finding']['model']}")
    logger.info(f"  Summary model: {config['summary_generation']['model']}")

    # Create output directory for this config (each PMCID gets its own file)
    config_name = config_info.get("name", "pipeline")
    output_dir = OUTPUTS_DIR / config_name
    logger.info(f"  Output directory: {output_dir}")

    # Run pipeline - results are saved incrementally as each PMCID completes
    output_dir, results = run_pipeline(pmcids, config, prompts, stages, output_dir)

    # Print summary
    total_variants = sum(len(r.variants) for r in results)
    total_associations = sum(
        len([a for a in r.associations if a.sentence]) for r in results
    )
    total_citations = sum(
        len([a for a in r.associations if a.citations]) for r in results
    )
    total_summaries = sum(1 for r in results if r.summary)

    logger.success(f"\nPipeline complete!")
    logger.success(f"Results saved to: {output_dir}")
    logger.info(f"\nPipeline Summary:")
    logger.info(f"  PMCIDs processed: {len(results)}")
    logger.info(f"  Total variants found: {total_variants}")
    logger.info(f"  Total associations: {total_associations}")
    logger.info(f"  Associations with citations: {total_citations}")
    logger.info(f"  Summaries generated: {total_summaries}")


if __name__ == "__main__":
    main()
